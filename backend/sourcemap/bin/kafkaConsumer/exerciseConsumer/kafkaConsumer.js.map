{"version":3,"file":"kafkaConsumer.js","sourceRoot":"","sources":["../../../../bin/kafkaConsumer/exerciseConsumer/kafkaConsumer.ts"],"names":[],"mappings":";;;AAAA,OAAO,CAAC,aAAa,CAAC,CAAC,MAAM,CAAC;IAC5B,gBAAgB,EAAE,OAAO,CAAC,GAAG,CAAC,QAAQ,KAAK,YAAY;CACxD,CAAC,CAAA;AAEF,6DAAiD;AAEjD,0DAAqC;AACrC,oEAA2C;AAC3C,oEAA2C;AAE3C,yDAAuD;AAEvD,uCAA6C;AAC7C,uCAA2C;AAC3C,uEAAmC;AAEnC,IAAM,UAAU,GAAG,CAAC,wBAAM,CAAC,iBAAiB,CAAC,UAAU,CAAC,CAAA;AAExD,IAAM,KAAK,GAAG,IAAI,uBAAK,EAAE,CAAA;AACzB,IAAM,MAAM,GAAG,mBAAY,EAAE,CAAA;AAE7B,IAAM,MAAM,GAAG,mBAAY,CAAC,EAAE,OAAO,EAAE,yBAAyB,EAAE,CAAC,CAAA;AAEnE,IAAM,SAAS,GAAG,UAAC,GAAQ,EAAE,eAAoB;IAC/C,IAAI,GAAG,EAAE;QACP,MAAM,CAAC,KAAK,CAAC,kBAAkB,GAAG,GAAG,CAAC,CAAA;KACvC;SAAM;QACL,MAAM,CAAC,IAAI,CAAC,6BAA6B,GAAG,eAAe,CAAC,CAAA;KAC7D;AACH,CAAC,CAAA;AAED,IAAM,QAAQ,GAAG,IAAI,KAAK,CAAC,aAAa,CACtC;IACE,UAAU,EAAE,OAAO;IACnB,sBAAsB,EAAE,OAAO,CAAC,GAAG,CAAC,UAAU;IAC9C,gBAAgB,EAAE,SAAS;IAC3B,oBAAoB,EAAE,KAAK;IAC3B,+BAA+B,EAAE,YAAY;CAC9C,EACD,EAAE,mBAAmB,EAAE,UAAU,EAAE,CACpC,CAAA;AAED,QAAQ,CAAC,OAAO,EAAE,CAAA;AAElB,QAAQ;KACL,EAAE,CAAC,OAAO,EAAE;IACX,QAAQ,CAAC,SAAS,CAAC,UAAU,CAAC,CAAA;IAC9B,QAAQ,CAAC,OAAO,EAAE,CAAA;AACpB,CAAC,CAAC;KACD,EAAE,CAAC,MAAM,EAAE,UAAC,OAAO;IAClB,OAAA,6BAAa,CAAU;QACrB,YAAY,EAAE,OAAO;QACrB,KAAK,OAAA;QACL,MAAM,QAAA;QACN,QAAQ,UAAA;QACR,MAAM,QAAA;QACN,gBAAgB,6BAAA;QAChB,cAAc,2BAAA;KACf,CAAC;AARF,CAQE,CACH,CAAA;AACH,QAAQ,CAAC,EAAE,CAAC,aAAa,EAAE,UAAC,KAAK;IAC/B,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAA;IACnB,MAAM,KAAK,CAAA;AACb,CAAC,CAAC,CAAA;AAEF,QAAQ,CAAC,EAAE,CAAC,WAAW,EAAE,UAAU,GAAG;IACpC,OAAO,CAAC,GAAG,CAAC,GAAG,CAAC,CAAA;AAClB,CAAC,CAAC,CAAA","sourcesContent":["require(\"dotenv-safe\").config({\n  allowEmptyValues: process.env.NODE_ENV === \"production\",\n})\n\nimport { Mutex } from \"../../lib/await-semaphore\"\n\nimport * as Kafka from \"node-rdkafka\"\nimport prismaClient from \"../../lib/prisma\"\nimport sentryLogger from \"../../lib/logger\"\n\nimport { handleMessage } from \"../common/handleMessage\"\nimport { Message } from \"./interfaces\"\nimport { MessageYupSchema } from \"./validate\"\nimport { saveToDatabase } from \"./saveToDB\"\nimport config from \"../kafkaConfig\"\n\nconst TOPIC_NAME = [config.exercise_consumer.topic_name]\n\nconst mutex = new Mutex()\nconst prisma = prismaClient()\n\nconst logger = sentryLogger({ service: \"kafka-consumer-exercise\" })\n\nconst logCommit = (err: any, topicPartitions: any) => {\n  if (err) {\n    logger.error(\"Error in commit:\" + err)\n  } else {\n    logger.info(\"Committed. topicPartitions:\" + topicPartitions)\n  }\n}\n\nconst consumer = new Kafka.KafkaConsumer(\n  {\n    \"group.id\": \"kafka\",\n    \"metadata.broker.list\": process.env.KAFKA_HOST,\n    offset_commit_cb: logCommit,\n    \"enable.auto.commit\": false,\n    \"partition.assignment.strategy\": \"roundrobin\",\n  },\n  { \"auto.offset.reset\": \"earliest\" },\n)\n\nconsumer.connect()\n\nconsumer\n  .on(\"ready\", () => {\n    consumer.subscribe(TOPIC_NAME)\n    consumer.consume()\n  })\n  .on(\"data\", (message) =>\n    handleMessage<Message>({\n      kafkaMessage: message,\n      mutex,\n      logger,\n      consumer,\n      prisma,\n      MessageYupSchema,\n      saveToDatabase,\n    }),\n  )\nconsumer.on(\"event.error\", (error) => {\n  logger.error(error)\n  throw error\n})\n\nconsumer.on(\"event.log\", function (log) {\n  console.log(log)\n})\n"]}